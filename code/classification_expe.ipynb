{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as scp\n",
    "from tqdm import tqdm\n",
    "from utils import ngsimDataset,maskedNLL,maskedMSE,maskedNLLTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maneuver_class(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size=128, num_layers = 1):\n",
    "        \n",
    "        super(Maneuver_class, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding = nn.Linear(input_size, 64)\n",
    "        self.hidden_size = 128\n",
    "        self.num_layers = 1\n",
    "\n",
    "        # define LSTM layer\n",
    "        self.lstm = nn.LSTM(64, hidden_size = 128,            # input 是 (sequence_size, batch_size, input_size)\n",
    "                            num_layers = 1, batch_first=False)       \n",
    "        self.lat_linear = nn.Linear(self.hidden_size, 3) \n",
    "        self.lon_linear = nn.Linear(self.hidden_size, 2) \n",
    "        \n",
    "        #define activation:\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(0.1)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        \n",
    "        embedded = self.embedding(x_input)\n",
    "        embedded = self.leaky_relu(embedded)\n",
    "        lstm_out, self.hidden = self.lstm(embedded)\n",
    "        lat_temp = self.lat_linear(lstm_out[-1])\n",
    "        lat_pred = self.softmax(lat_temp)\n",
    "        \n",
    "        lon_temp = self.lon_linear(lstm_out[-1])\n",
    "        lon_pred = self.softmax(lon_temp)\n",
    "        \n",
    "        \n",
    "        return  lat_pred, lon_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3])\n",
      "torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(batch_size, t_h): #假设 t_h = 8\n",
    "    inputs = torch.randn(t_h, batch_size, 14) # len(features) = 14\n",
    "    return inputs\n",
    "input_mc = prepare_data(20, 8)\n",
    "classmodel = Maneuver_class(14)\n",
    "lat_pred, lon_pred = classmodel(input_mc)\n",
    "print(lat_pred.shape)\n",
    "print(lon_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred, target):\n",
    "    loss = -np.sum(target * np.log(pred))\n",
    "    return loss/float(pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_loader, loss_fn):\n",
    "    model.eval()\n",
    "    valid_loss = 0.\n",
    "    for data in tqdm(valid_loader):\n",
    "        hist, nbrs, mask, lat_enc, lon_enc, fut, op_mas = data\n",
    "        hist,nbrs,lat_enc, lon_enc= hist.to(device), nbrs.to(device), lat_enc.to(device), lon_enc.to(device)\n",
    "        lat_pred, lon_pred = model(hist)    \n",
    "        lat_loss = loss_fn(lat_pred, lat_enc)\n",
    "        lon_loss = loss_fn(lon_pred, lon_enc)\n",
    "            \n",
    "        loss = lat_loss + lon_loss\n",
    "        valid_loss += loss.item()\n",
    "    return valid_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_dir, input_size, n_epochs=100, _batch_size=1, _lr = 0.001, load_model=False, model_path='output/model0.pth'):\n",
    "\n",
    "    trSet = ngsimDataset(data_dir+'TrainSet.mat')\n",
    "    valSet = ngsimDataset(data_dir+'ValSet.mat')\n",
    "    trDataloader = DataLoader(trSet,batch_size=_batch_size,shuffle=True,collate_fn=trSet.collate_fn)\n",
    "    valDataloader = DataLoader(valSet,batch_size=_batch_size,shuffle=True,collate_fn=valSet.collate_fn)\n",
    "    # training\n",
    "    model = Maneuver_class(input_size).to(device) # 目前尝试只考虑本车：input_size=2\n",
    "\n",
    "    if load_model == True:\n",
    "        ckpt = torch.load(model_path)\n",
    "        model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=_lr)\n",
    "        \n",
    "    min_loss = 100.  # why?\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        it = 0\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    " \n",
    "        for data in tqdm(trDataloader):\n",
    "            hist, nbrs, mask, lat_enc, lon_enc, fut, op_mas = data\n",
    "            hist,nbrs,lat_enc, lon_enc = hist.to(device), nbrs.to(device), lat_enc.to(device), lon_enc.to(device)  #缺一个padding方法,目前input_size要设置为2\n",
    "            lat_pred, lon_pred = model(hist)\n",
    "            \n",
    "            lat_loss = loss_fn(lat_pred, lat_enc)\n",
    "            lon_loss = loss_fn(lon_pred, lon_enc)\n",
    "            \n",
    "            loss = lat_loss + lon_loss\n",
    "            # zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "                          \n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            it += 1\n",
    "            if it%500==0:\n",
    "                print(\"Training Iteration {} of epoch {} complete. Loss: {}\".\n",
    "                    format(it, epoch, loss.item()))\n",
    "\n",
    "        epoch_loss = total_loss/len(trDataloader)\n",
    "        print('epoch:{},avg_loss:{}'.format(epoch, epoch_loss))\n",
    "        #save best model\n",
    "        if epoch_loss < min_loss:\n",
    "            min_loss = epoch_loss\n",
    "            torch.save({'epoch': epoch, 'state_dict': model.state_dict()},\n",
    "                           'output/model_{}.pth'.format(epoch))\n",
    "            print(\"epoch:%d Model Saved\" % epoch)\n",
    "\n",
    "        #validation\n",
    "        if epoch % 10 == 0:\n",
    "            valid_loss = valid(model, valDataloader, loss_fn)\n",
    "            print('validation epoch:{},valid_loss:{}'.format(epoch, valid_loss))\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 527/5922867 [00:04<11:11:46, 146.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 500 of epoch 0 complete. Loss: 0.4189721345901489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1018/5922867 [00:07<12:29:20, 131.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 1000 of epoch 0 complete. Loss: 0.2595510482788086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1515/5922867 [00:11<10:52:24, 151.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 1500 of epoch 0 complete. Loss: 0.1260056048631668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2015/5922867 [00:14<14:33:55, 112.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 2000 of epoch 0 complete. Loss: 0.9727218747138977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2520/5922867 [00:18<13:01:02, 126.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 2500 of epoch 0 complete. Loss: 0.37654462456703186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3013/5922867 [00:22<13:33:48, 121.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 3000 of epoch 0 complete. Loss: 2.6680634021759033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3527/5922867 [00:26<14:19:38, 114.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 3500 of epoch 0 complete. Loss: 0.11133483797311783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4027/5922867 [00:30<11:22:47, 144.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 4000 of epoch 0 complete. Loss: 0.07220134139060974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4528/5922867 [00:33<10:46:56, 152.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 4500 of epoch 0 complete. Loss: 0.1188773438334465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5023/5922867 [00:37<13:13:29, 124.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 5000 of epoch 0 complete. Loss: 1.1283870935440063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5525/5922867 [00:41<12:49:25, 128.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 5500 of epoch 0 complete. Loss: 0.25366970896720886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6025/5922867 [00:45<12:19:23, 133.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 6000 of epoch 0 complete. Loss: 0.12776094675064087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6518/5922867 [00:50<17:49:02, 92.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 6500 of epoch 0 complete. Loss: 0.06721433252096176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7025/5922867 [00:54<11:48:53, 139.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 7000 of epoch 0 complete. Loss: 0.4834219813346863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7520/5922867 [00:59<12:34:43, 130.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 7500 of epoch 0 complete. Loss: 0.42419925332069397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8022/5922867 [01:03<12:21:40, 132.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 8000 of epoch 0 complete. Loss: 0.08208039402961731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8523/5922867 [01:07<12:58:28, 126.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 8500 of epoch 0 complete. Loss: 1.5559724569320679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9023/5922867 [01:10<11:42:21, 140.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 9000 of epoch 0 complete. Loss: 0.09450817108154297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9525/5922867 [01:14<11:35:28, 141.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 9500 of epoch 0 complete. Loss: 2.1284477710723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10022/5922867 [01:18<12:32:06, 131.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 10000 of epoch 0 complete. Loss: 0.0983513817191124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10528/5922867 [01:22<11:23:57, 144.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 10500 of epoch 0 complete. Loss: 0.21564935147762299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11022/5922867 [01:26<12:39:23, 129.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 11000 of epoch 0 complete. Loss: 0.3915429711341858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11525/5922867 [01:30<13:45:04, 119.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 11500 of epoch 0 complete. Loss: 1.6647355556488037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12024/5922867 [01:34<14:06:59, 116.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 12000 of epoch 0 complete. Loss: 0.1953759640455246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12524/5922867 [01:38<13:13:49, 124.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 12500 of epoch 0 complete. Loss: 4.433499336242676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13021/5922867 [01:42<12:02:10, 136.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 13000 of epoch 0 complete. Loss: 0.03486473113298416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13528/5922867 [01:46<11:47:18, 139.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 13500 of epoch 0 complete. Loss: 0.14394450187683105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14026/5922867 [01:50<12:11:09, 134.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 14000 of epoch 0 complete. Loss: 0.2779296636581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14527/5922867 [01:54<12:03:11, 136.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 14500 of epoch 0 complete. Loss: 0.25119680166244507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15013/5922867 [01:58<12:48:00, 128.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 15000 of epoch 0 complete. Loss: 0.2099154144525528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15520/5922867 [02:01<12:32:00, 130.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 15500 of epoch 0 complete. Loss: 0.21651123464107513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16021/5922867 [02:05<12:59:52, 126.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 16000 of epoch 0 complete. Loss: 1.0933839082717896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16514/5922867 [02:10<14:57:15, 109.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 16500 of epoch 0 complete. Loss: 0.11075998842716217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16864/5922867 [02:13<12:58:35, 126.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_602/3148858418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/mnt/e/Northwestern University/Courses/2022winter/pattern recognition/projects/data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output/model0.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_602/3605159791.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data_dir, input_size, n_epochs, _batch_size, _lr, load_model, model_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlon_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# zero the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = '/mnt/e/Northwestern University/Courses/2022winter/pattern recognition/projects/data/'\n",
    "train_model(data_dir, 2, n_epochs=100, _batch_size=1, _lr = 0.001, load_model=False, model_path='output/model0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data_dir, _batch_size=16, model_path = 'output/model0.pth'):\n",
    "    testSet = ngsimDataset(data_dir+'TestSet.mat')\n",
    "    test_loader = DataLoader(testSet,batch_size=_batch_size,shuffle=False,collate_fn=testSet.collate_fn)\n",
    "    \n",
    "    model = Maneuver_class(14,128).to(device)\n",
    "    ckpt = torch.load(model_path)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    for data in tqdm(test_loader):\n",
    "        hist, nbrs, mask, lat_enc, lon_enc, fut, op_mas = data\n",
    "        hist,nbrs,lat_enc, lon_enc = hist.to(device), nbrs.to(device), lat_enc.to(device), lon_enc.to(device) \n",
    "        lat_pred, lon_pred = model(hist)  #这里还缺padding 操作"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "025c2a054364216e55d81e515f6bbe31fc3926bc9f850f0168c12f6592bdfec8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
