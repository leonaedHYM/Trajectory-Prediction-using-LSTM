{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "4c89faca-8d30-408b-81f9-6ae059960914",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3639,
    "execution_start": 1646415417203,
    "source_hash": "cc073d12"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "#from utils import ngsimDataset,maskedNLL,maskedMSE,maskedNLLTest\n",
    "import time\n",
    "import math\n",
    "from __future__ import print_function, division\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as scp\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": "00001-2da24d25-d2dd-4535-b498-6e1b3a85e5d3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646415434427,
    "source_hash": "561fe37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": "00002-5638fad8-9cae-414f-b4a6-ff8de29d5758",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1646363682669,
    "source_hash": "c1d46c8a"
   },
   "outputs": [],
   "source": [
    "def prepare_data(batch_size, t_h): #假设 t_h = 8\n",
    "    inputs = torch.randn(batch_size, t_h, 2) # len(features) = 14\n",
    "    return inputs    # batch_size, seq_length, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-02bdf610-b0a1-4f9e-ac7c-6a70c3705e8c",
    "deepnote_cell_type": "markdown",
    "id": "fS25_0cRG-hg"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": "00009-e584b890-3dd4-452b-9f91-8acce2f9ed0f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1646415581379,
    "source_hash": "e300c711"
   },
   "outputs": [],
   "source": [
    "class lstm_encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers = 1):\n",
    "        \n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding = nn.Linear(input_size, 64)\n",
    "        self.hidden_size = 128\n",
    "        self.num_layers = 1\n",
    "\n",
    "        # define LSTM layer\n",
    "        self.lstm = nn.LSTM(64, hidden_size = 128,  # input 是 (batch_size, sequence_size, input_size)\n",
    "                            num_layers = 1, batch_first=False)       \n",
    "\n",
    "        #define activation:\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(0.1)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        \n",
    "        embedded = self.embedding(x_input)\n",
    "        embedded = self.leaky_relu(embedded)\n",
    "        lstm_out, self.hidden = self.lstm(embedded)\n",
    "        \n",
    "        \n",
    "        return lstm_out, self.hidden     \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": "00010-29c37863-4737-4cd6-903b-6b9a06932214",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646363682737,
    "source_hash": "2465bf7c"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1729)\n",
    "inputs = prepare_data(20, 8)\n",
    "input_sizes = 2\n",
    "encoder = lstm_encoder(input_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": "00011-3901404d-8108-40f4-8021-77710273b9bc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 69,
    "execution_start": 1646363686431,
    "source_hash": "6907c171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 20, 2])\n",
      "torch.Size([8, 20, 128])\n",
      "torch.Size([1, 20, 128])\n",
      "torch.Size([1, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(batch_size, t_h): #假设 t_h = 8\n",
    "    inputs = torch.randn(t_h,batch_size, 2) # len(features) = 2\n",
    "    return inputs    # seq_length,  batch_size, features\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "inputs = prepare_data(20, 8)\n",
    "input_sizes = 2\n",
    "encoder = lstm_encoder(input_sizes)\n",
    "\n",
    "output, hidden = encoder(inputs)  \n",
    "print(inputs.shape)\n",
    "print(output.shape) # output: [time, batch, features]\n",
    "print(hidden[0].shape)\n",
    "print(hidden[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-2e9cc683-2754-40cf-9635-b24c46c7916c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "从Encoder到decoder的维度拼接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00013-55bf33a6-b3a5-43dc-8404-12a4b5ac8097",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646415583627,
    "source_hash": "64db8503"
   },
   "outputs": [],
   "source": [
    "def one_hot_coding(batch_size):\n",
    "    m_class = torch.zeros(6,6)\n",
    "    for i in range(0,6):\n",
    "        m_class[i][i] = 1\n",
    "    one_hot = torch.empty(6,batch_size,6)\n",
    "    for i in range(6):\n",
    "        temp = m_class[i].view(1,-1)\n",
    "        for j in range(0, batch_size-1):\n",
    "            \n",
    "            temp = torch.cat((temp,m_class[i].view(1,-1)))\n",
    "        one_hot[i] = temp\n",
    "    return one_hot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "6e4581a9-4560-40f5-8597-441d3eb4140e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1646415586256,
    "source_hash": "980dc2a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_output(output, one_hot,batch_size):\n",
    "    dec_input = torch.empty(6,batch_size,134)\n",
    "    for i in range(6):\n",
    "        dec_input[i] = torch.cat((output[0], one_hot[i]),1)\n",
    "        \n",
    "    return dec_input.view(dec_input.shape[0],1,batch_size,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "00014-dcefe5e1-b482-4ac2-8742-90cd9e94394a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646415588294,
    "source_hash": "56c91768"
   },
   "outputs": [],
   "source": [
    "class lstm_decoder(nn.Module):\n",
    "    ''' Decodes hidden state output by encoder '''\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_size=128, num_layers = 1):\n",
    "\n",
    "        \n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = 128\n",
    "        self.num_layers = 1\n",
    "        #self.embedding = nn.Linear(input_size, 64)\n",
    "        self.lstm = nn.LSTM(134, hidden_size = self.hidden_size,\n",
    "                            num_layers = self.num_layers, batch_first=False)\n",
    "        self.linear = nn.Linear(self.hidden_size, output_size)           \n",
    "\n",
    "    def forward(self, encoder_hidden_cat, hidden):\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(encoder_hidden_cat, hidden)   # use encoder's final hidden state concatted with one-hot as input\n",
    "        output = self.linear(lstm_out)     \n",
    "        return output, self.hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        \n",
    "        # (self.n_layers, batch_size, self.hidden_dim)\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
    "                torch.zeros(1, batch_size, self.hidden_size)) \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": "00015-3e25ab0b-0003-441b-83f1-ce38a07165a6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646415790399,
    "source_hash": "65121bdf"
   },
   "outputs": [],
   "source": [
    "class lstm_seq2seq(nn.Module):\n",
    "    ''' train LSTM encoder-decoder'''\n",
    "    \n",
    "    def __init__(self, enc_input_size, hidden_size=128, output_timestep = 25, output_size = 2):\n",
    "\n",
    "        super(lstm_seq2seq, self).__init__()\n",
    "\n",
    "        self.enc_input_size = enc_input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.encoder = lstm_encoder(self.enc_input_size)\n",
    "        self.decoder = lstm_decoder(input_size=134, output_size=2)   # outputsize is tricky\n",
    "        #self.encoder_hidden = self.encoder.init_hidden(batch_size)\n",
    "    \n",
    "    def forward(self, hist, nbr, target_batch, loss_fn, output_timestep=25, batch_size=1):\n",
    "        #how to concatenate hist and nbr to input_batch: concat on third dim, and padding\n",
    "        input_batch = hist          # 只尝试本车\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder(input_batch)\n",
    "        # use concatted encoder_hidden_states as decoder's input \n",
    "        \n",
    "        batch_loss = 0.\n",
    "        decoder_hidden = self.decoder.init_hidden(batch_size)\n",
    "        one_hot = one_hot_coding(batch_size)\n",
    "        decoder_input_all = concat_output(encoder_output, one_hot, batch_size=1)  \n",
    "        for i in range(0,6):\n",
    "            pred = torch.empty(25,batch_size, 2)\n",
    "            decoder_input = decoder_input_all[i]\n",
    "            for j in range(output_timestep):\n",
    "            #decoder outputs \n",
    "                temp, decoder_output_hidden = self.decoder.forward(decoder_input, decoder_hidden)    # decoder的输入是encoder的hidden_state 与 one_hot concat在一起\n",
    "                pred[j] = temp.squeeze()\n",
    "                decoder_hidden = decoder_output_hidden                                                       \n",
    "            \n",
    "            #computing loss\n",
    "            loss = loss_fn(pred, target_batch)   # pred:[25,batch_size,2], target:[25,batch_size,2]  # how to compute NLLloss?\n",
    "            batch_loss += loss\n",
    "\n",
    "        return batch_loss, pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-9b057be0-b5fc-4197-a4c2-94c4b30e8ed0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 26,
    "execution_start": 1646414593475,
    "source_hash": "3d085346"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bb31a3052eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "decoder = lstm_decoder(input_size=128, output_size=2)\n",
    "decoder_output, decoder_hidden = decoder(output, cat_hidden_states)\n",
    "print(decoder_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-938b0713-d0a0-46b5-bde7-7d2243bcb125",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "819e1cc2-b0c1-4a5f-b996-f5a9eca39e3a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1646415793747,
    "source_hash": "2f206242",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.\n",
    "    for data in tqdm(valid_loader):\n",
    "        hist, nbrs, _, _, _, fut, _ = data\n",
    "        hist,nbrs,fut = hist.to(device), nbrs.to(device), fut.to(device)\n",
    "        loss,_ = model(hist, nbrs, fut)\n",
    "        valid_loss += loss.item()\n",
    "    return valid_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "a76c0d31-f20a-4011-bb02-e9fa6ef568df",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1646415796347,
    "source_hash": "61398cca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(data_dir, n_epochs=100, _batch_size=1, _lr = 0.001, load_model=False, model_path='output/model0.pth'):\n",
    "\n",
    "    trSet = ngsimDataset(data_dir+'TrainSet.mat')\n",
    "    valSet = ngsimDataset(data_dir+'ValSet.mat')\n",
    "    trDataloader = DataLoader(trSet,batch_size=_batch_size,shuffle=True,collate_fn=trSet.collate_fn)\n",
    "    valDataloader = DataLoader(valSet,batch_size=_batch_size,shuffle=True,collate_fn=valSet.collate_fn)\n",
    "    # training\n",
    "    model = lstm_seq2seq(2).to(device) # 目前尝试只考虑本车：input_size=2\n",
    "\n",
    "    if load_model == True:\n",
    "        ckpt = torch.load(model_path)\n",
    "        model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=_lr)\n",
    "        \n",
    "    min_loss = 100.  # why?\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for data in tqdm(trDataloader):\n",
    "            hist, nbrs, _, _, _, fut, _ = data\n",
    "            hist,nbrs,fut = hist.to(device), nbrs.to(device), fut.to(device)\n",
    "            loss,_ = model(hist, nbrs, fut, loss_fn, output_timestep=25, batch_size=1)\n",
    "\n",
    "            # zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "                          \n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        epoch_loss = total_loss/len(trDataloader)\n",
    "        print('epoch:{},avg_loss:{}'.format(epoch, epoch_loss))\n",
    "        #save best model\n",
    "        if epoch_loss < min_loss:\n",
    "            min_loss = epoch_loss\n",
    "            torch.save({'epoch': epoch, 'state_dict': model.state_dict()},\n",
    "                           'output/model_{}.pth'.format(epoch))\n",
    "            print(\"epoch:%d Model Saved\" % epoch)\n",
    "\n",
    "        #validation\n",
    "        if epoch % 10 == 0:\n",
    "            valid_loss = valid(model, valDataloader)\n",
    "            print('validation epoch:{},valid_loss:{}'.format(epoch, valid_loss))\n",
    "            model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": "eea7dc75-6689-481b-8249-6d7a7943d743",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12142,
    "execution_start": 1646415798624,
    "source_hash": "eebdece8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2431/5922867 [04:34<185:30:14,  8.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_474/3833602599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/mnt/e/Northwestern University/Courses/2022winter/pattern recognition/projects/data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output/model0.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_474/61219037.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data_dir, n_epochs, _batch_size, _lr, load_model, model_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnbrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_timestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# zero the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_474/2667953835.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hist, nbr, target_batch, loss_fn, output_timestep, batch_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_timestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#decoder outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# decoder的输入是encoder的hidden_state 与 one_hot concat在一起\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_474/636925522.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_hidden_cat, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# use encoder's final hidden state concatted with one-hot as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir='/mnt/e/Northwestern University/Courses/2022winter/pattern recognition/projects/data/'\n",
    "train_model(data_dir, n_epochs=100, _batch_size=1, _lr = 0.001, load_model=False, model_path='output/model0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "be565dac-5249-40c7-bead-530ff0c741a9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "219407b2-de28-4088-9601-e0e01bf1c2ce",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(data_dir, _batch_size=16, model_path = 'output/model0.pth'):\n",
    "    testSet = ngsimDataset(data_dir+'TestSet.mat')\n",
    "    test_loader = DataLoader(testSet,batch_size=_batch_size,shuffle=False,collate_fn=testSet.collate_fn)\n",
    "    \n",
    "    model = lstm_seq2seq(14,128).to(device)\n",
    "    ckpt = torch.load(model_path)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    for data in tqdm(test_loader):\n",
    "        hist, nbrs, _, _, _, fut, _ = data\n",
    "        hist,nbrs,fut = hist.to(device), nbrs.to(device), fut.to(device)\n",
    "        _,pred = model(hist, nbrs, fut)\n",
    "\n",
    "        #multiply with manuver probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngsimDataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, mat_file, t_h=30, t_f=50, d_s=2, enc_size = 64, grid_size = (13,3)):\n",
    "        self.D = scp.loadmat(mat_file)['traj']\n",
    "        self.T = scp.loadmat(mat_file)['tracks']\n",
    "        self.t_h = t_h  # length of track history\n",
    "        self.t_f = t_f  # length of predicted trajectory\n",
    "        self.d_s = d_s  # down sampling rate of all sequences\n",
    "        self.enc_size = enc_size # size of encoder LSTM\n",
    "        self.grid_size = grid_size # size of social context grid\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.D)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        dsId = self.D[idx, 0].astype(int)\n",
    "        vehId = self.D[idx, 1].astype(int)\n",
    "        t = self.D[idx, 2]\n",
    "        grid = self.D[idx,8:]\n",
    "        neighbors = []\n",
    "\n",
    "        # Get track history 'hist' = ndarray, and future track 'fut' = ndarray\n",
    "        hist = self.getHistory(vehId,t,vehId,dsId)\n",
    "        fut = self.getFuture(vehId,t,dsId)\n",
    "\n",
    "        # Get track histories of all neighbours 'neighbors' = [ndarray,[],ndarray,ndarray]\n",
    "        for i in grid:\n",
    "            neighbors.append(self.getHistory(i.astype(int), t,vehId,dsId))\n",
    "\n",
    "        # Maneuvers 'lon_enc' = one-hot vector, 'lat_enc = one-hot vector\n",
    "        lon_enc = np.zeros([2])\n",
    "        lon_enc[int(self.D[idx, 7] - 1)] = 1\n",
    "        lat_enc = np.zeros([3])\n",
    "        lat_enc[int(self.D[idx, 6] - 1)] = 1\n",
    "\n",
    "        return hist,fut,neighbors,lat_enc,lon_enc\n",
    "\n",
    "\n",
    "\n",
    "    ## Helper function to get track history\n",
    "    def getHistory(self,vehId,t,refVehId,dsId):\n",
    "        if vehId == 0:\n",
    "            return np.empty([0,2])\n",
    "        else:\n",
    "            if self.T.shape[1]<=vehId-1:\n",
    "                return np.empty([0,2])\n",
    "            refTrack = self.T[dsId-1][refVehId-1].transpose()\n",
    "            vehTrack = self.T[dsId-1][vehId-1].transpose()\n",
    "            refPos = refTrack[np.where(refTrack[:,0]==t)][0,1:3]\n",
    "\n",
    "            if vehTrack.size==0 or np.argwhere(vehTrack[:, 0] == t).size==0:\n",
    "                 return np.empty([0,2])\n",
    "            else:\n",
    "                stpt = np.maximum(0, np.argwhere(vehTrack[:, 0] == t).item() - self.t_h)\n",
    "                enpt = np.argwhere(vehTrack[:, 0] == t).item() + 1\n",
    "                hist = vehTrack[stpt:enpt:self.d_s,1:3]-refPos\n",
    "\n",
    "            if len(hist) < self.t_h//self.d_s + 1:\n",
    "                return np.empty([0,2])\n",
    "            return hist\n",
    "\n",
    "\n",
    "\n",
    "    ## Helper function to get track future\n",
    "    def getFuture(self, vehId, t,dsId):\n",
    "        vehTrack = self.T[dsId-1][vehId-1].transpose()\n",
    "        refPos = vehTrack[np.where(vehTrack[:, 0] == t)][0, 1:3]\n",
    "        stpt = np.argwhere(vehTrack[:, 0] == t).item() + self.d_s\n",
    "        enpt = np.minimum(len(vehTrack), np.argwhere(vehTrack[:, 0] == t).item() + self.t_f + 1)\n",
    "        fut = vehTrack[stpt:enpt:self.d_s,1:3]-refPos\n",
    "        return fut\n",
    "\n",
    "\n",
    "\n",
    "    ## Collate function for dataloader\n",
    "    def collate_fn(self, samples):\n",
    "\n",
    "        # Initialize neighbors and neighbors length batches:\n",
    "        nbr_batch_size = 0\n",
    "        for _,_,nbrs,_,_ in samples:\n",
    "            nbr_batch_size += sum([len(nbrs[i])!=0 for i in range(len(nbrs))])\n",
    "        maxlen = self.t_h//self.d_s + 1\n",
    "        nbrs_batch = torch.zeros(maxlen,nbr_batch_size,2)\n",
    "\n",
    "\n",
    "        # Initialize social mask batch:\n",
    "        pos = [0, 0]\n",
    "        mask_batch = torch.zeros(len(samples), self.grid_size[1],self.grid_size[0],self.enc_size)\n",
    "        mask_batch = mask_batch.byte()\n",
    "\n",
    "\n",
    "        # Initialize history, history lengths, future, output mask, lateral maneuver and longitudinal maneuver batches:\n",
    "        hist_batch = torch.zeros(maxlen,len(samples),2)\n",
    "        fut_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n",
    "        op_mask_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n",
    "        lat_enc_batch = torch.zeros(len(samples),3)\n",
    "        lon_enc_batch = torch.zeros(len(samples), 2)\n",
    "\n",
    "\n",
    "        count = 0\n",
    "        for sampleId,(hist, fut, nbrs, lat_enc, lon_enc) in enumerate(samples):\n",
    "\n",
    "            # Set up history, future, lateral maneuver and longitudinal maneuver batches:\n",
    "            hist_batch[0:len(hist),sampleId,0] = torch.from_numpy(hist[:, 0])\n",
    "            hist_batch[0:len(hist), sampleId, 1] = torch.from_numpy(hist[:, 1])\n",
    "            fut_batch[0:len(fut), sampleId, 0] = torch.from_numpy(fut[:, 0])\n",
    "            fut_batch[0:len(fut), sampleId, 1] = torch.from_numpy(fut[:, 1])\n",
    "            op_mask_batch[0:len(fut),sampleId,:] = 1\n",
    "            lat_enc_batch[sampleId,:] = torch.from_numpy(lat_enc)\n",
    "            lon_enc_batch[sampleId, :] = torch.from_numpy(lon_enc)\n",
    "\n",
    "            # Set up neighbor, neighbor sequence length, and mask batches:\n",
    "            for id,nbr in enumerate(nbrs):\n",
    "                if len(nbr)!=0:\n",
    "                    nbrs_batch[0:len(nbr),count,0] = torch.from_numpy(nbr[:, 0])\n",
    "                    nbrs_batch[0:len(nbr), count, 1] = torch.from_numpy(nbr[:, 1])\n",
    "                    pos[0] = id % self.grid_size[0]\n",
    "                    pos[1] = id // self.grid_size[0]\n",
    "                    mask_batch[sampleId,pos[1],pos[0],:] = torch.ones(self.enc_size).byte()\n",
    "                    count+=1\n",
    "\n",
    "        return hist_batch, nbrs_batch, mask_batch, lat_enc_batch, lon_enc_batch, fut_batch, op_mask_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=08756b88-eec3-4b1b-a0c9-04763ec70cac' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "1e42c6b0-1cd7-4d43-944f-1027a04a1868",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
